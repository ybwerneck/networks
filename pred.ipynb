{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066d453-f9ee-454e-bb2f-4ea4eba54867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27d42d4-0922-46f7-80fb-344ae2d36a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:16:58.644517Z",
     "iopub.status.busy": "2023-05-07T18:16:58.644195Z",
     "iopub.status.idle": "2023-05-07T18:16:58.657585Z",
     "shell.execute_reply": "2023-05-07T18:16:58.657008Z",
     "shell.execute_reply.started": "2023-05-07T18:16:58.644501Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fhn1Ppred.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fhn1Ppred.py\n",
    "\n",
    "from modulus.models.fully_connected import FullyConnectedArch\n",
    "from modulus.models.fourier_net import FourierNetArch\n",
    "from modulus.models.siren import SirenArch\n",
    "from modulus.models.modified_fourier_net import ModifiedFourierNetArch\n",
    "from modulus.models.dgm import DGMArch\n",
    "\n",
    "from sympy import Symbol, Eq\n",
    "from sympy import Symbol, Function, Number\n",
    "from modulus.eq.pde import PDE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import modulus\n",
    "from modulus.hydra import instantiate_arch, ModulusConfig\n",
    "from modulus.solver import Solver\n",
    "from modulus.domain import Domain\n",
    "from modulus.geometry.primitives_1d import Point1D\n",
    "from modulus.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseInteriorConstraint,\n",
    ")\n",
    "from modulus.domain.validator import PointwiseValidator\n",
    "from modulus.key import Key\n",
    "from modulus.node import Node\n",
    "from modulus.eq.pde import PDE\n",
    "from modulus.geometry import Parameterization\n",
    "from sympy import Symbol, Eq, Abs, tanh, Or, And\n",
    "from modulus.utils.io import (\n",
    "    csv_to_dict,\n",
    "    ValidatorPlotter,\n",
    "    InferencerPlotter,\n",
    ")\n",
    "from modulus.solver import SequentialSolver\n",
    "\n",
    "from modulus.models.deeponet import DeepONetArch\n",
    "from modulus.domain.constraint.continuous import DeepONetConstraint\n",
    "from modulus.models.moving_time_window import MovingTimeWindowArch\n",
    "from modulus.domain.monitor import Monitor\n",
    "from modulus.domain.constraint import Constraint\n",
    "from modulus.graph import Graph\n",
    "from modulus.key import Key\n",
    "from modulus.constants import TF_SUMMARY\n",
    "from modulus.distributed import DistributedManager\n",
    "from modulus.utils.io import dict_to_csv, csv_to_dict\n",
    "from modulus.domain.inferencer.pointwise import PointwiseInferencer as PointwiseInferencer\n",
    "from modulus.loss.loss import CausalLossNorm\n",
    "\n",
    "  \n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.cuda.profiler as profiler\n",
    "import torch.distributed as dist\n",
    "from termcolor import colored, cprint\n",
    "from copy import copy\n",
    "from operator import add\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Optional\n",
    "import logging\n",
    "from contextlib import ExitStack\n",
    "from typing import List, Union, Tuple, Callable\n",
    "\n",
    "\n",
    "from modulus.domain.constraint import Constraint\n",
    "from modulus.domain import Domain\n",
    "from modulus.loss.aggregator import Sum\n",
    "from modulus.utils.training.stop_criterion import StopCriterion\n",
    "from modulus.constants import TF_SUMMARY, JIT_PYTORCH_VERSION\n",
    "from modulus.hydra import (\n",
    "    instantiate_optim,\n",
    "    instantiate_sched,\n",
    "    instantiate_agg,\n",
    "    add_hydra_run_path,\n",
    ")\n",
    "from modulus.distributed.manager import DistributedManager\n",
    "\n",
    "import contextlib\n",
    "import io\n",
    "import sys\n",
    "import time as TIME\n",
    "from load import load\n",
    "global nw\n",
    "t_max = 10.0\n",
    "n_w=1\n",
    "t_w= t_max/n_w    \n",
    "class SSolver(SequentialSolver):\n",
    "    def __init__(  self,\n",
    "        cfg: DictConfig,\n",
    "        domains: List[Tuple[int, Domain]],\n",
    "        custom_update_operation: Union[Callable, None] = None,\n",
    "    ):\n",
    "        SequentialSolver.__init__(self,cfg,domains,custom_update_operation)\n",
    "  \n",
    "\n",
    "    \n",
    "    @property\n",
    "    def network_dir(self):\n",
    "        dir_name =\"/home/jovyan/final/1P/outputs/fhn1P/\"+ self.domain.name\n",
    "        if self.domains[self.domain_index][0] > 1:\n",
    "            dir_name += \"_\" + str(self.iteration_index).zfill(4)\n",
    "        return dir_name\n",
    "\n",
    "    def setnetwork_dir(self,dir):\n",
    "        self.network_dir=dir\n",
    "    def eval(\n",
    "        self,\n",
    "    ):\n",
    "        # check the directory exists\n",
    "\n",
    "\n",
    "        # create global model for restoring and saving\n",
    "\n",
    "    \n",
    "        #print(self.domains)\n",
    "        for domain_index in range(0, len(self.domains)):\n",
    "                # solve for number of iterations in train_domain\n",
    "            for iteration_index in range(0, self.domains[domain_index][0]   ):\n",
    "\n",
    "                    # set internal domain index and iteration index\n",
    "                    self.domain_index = domain_index\n",
    "                    self.iteration_index=iteration_index \n",
    "                    self.log.info(\n",
    "                        \"Predicting for Domain \"\n",
    "                        + str(self.domain.name)\n",
    "                        + \", iteration \"\n",
    "                        + str(self.iteration_index)\n",
    "                    )\n",
    "                    \n",
    "                    if not os.path.exists(self.network_dir):\n",
    "                        print(os.getcwd()+self.network_dir)\n",
    "                        raise RuntimeError(\"Network checkpoint is required for eval mode.\")\n",
    "                    self.saveable_models = self.get_saveable_models()\n",
    "\n",
    "        # set device\n",
    "                    if self.device is None:\n",
    "                        self.device = self.manager.device\n",
    "\n",
    "        # load model\n",
    "                    self.step = self.load_step()\n",
    "                    self.step = self.load_model()\n",
    "                    self.step_str = f\"[step: {self.step:10d}]\"\n",
    "\n",
    "                    # make summary writer\n",
    "                    self.writer = SummaryWriter(\n",
    "                        log_dir=self.network_dir, purge_step=self.summary_freq + 1\n",
    "                    )\n",
    "                    self.summary_histograms = self.cfg[\"summary_histograms\"]\n",
    "\n",
    "                    if self.manager.cuda:\n",
    "                        torch.cuda.synchronize(self.device)\n",
    "\n",
    "                    # write inference / validation datasets to tensorboard and file\n",
    "                    if self.has_validators:\n",
    "                        self._record_validators(self.step)\n",
    "                    if self.has_inferencers:\n",
    "                        self._record_inferencers(self.step)\n",
    "                    if self.has_monitors:\n",
    "                        self._record_monitors(self.step)\n",
    "\n",
    "def generateExactSolution(t,dt,x0,rate,P,begin,end):\n",
    "    \n",
    "    \n",
    "    n2=int(t/(dt))+2\n",
    "    n = int((end-begin)/(dt*rate))\n",
    "    Sol=np.zeros((n,3))\n",
    "  \n",
    "    return Sol\n",
    "def generateValidator(w_i,nodes):\n",
    "\n",
    "    \n",
    "    #print(np.shape(X))\n",
    "    if(n_w==1):\n",
    "        T=Input\n",
    "    else:\n",
    "        T=Input[w_i]-w_i\n",
    "    print(len(X0))\n",
    "    print(np.shape(X0))\n",
    "    print(\"lenT\",len(T))\n",
    "    t=np.zeros(len(T)*len(X0))\n",
    "    x=np.zeros(len(T)*len(X0))\n",
    "\n",
    "    i=0\n",
    "    k=0\n",
    "    j=0\n",
    "    print(T)\n",
    "    for x0 in X0:\n",
    "        j=0\n",
    "        for tt in T:\n",
    "            t[i]=T[j]\n",
    "            x[i]=X0[k]\n",
    "            i=i+1\n",
    "            j=j+1\n",
    "        k=k+1\n",
    "    print(t,x)\n",
    "    #print(np.shape(ASD))\n",
    "    invar_numpy = {\"t\":np.expand_dims( t,-1),\"K\":np.expand_dims(x,-1)}\n",
    "    outvar = {\"x1\",\"w\"}\n",
    "   \n",
    "    validator = PointwiseInferencer(\n",
    "        nodes=nodes, invar=invar_numpy,\n",
    "        output_names=outvar, batch_size=len(X0)*100,plotter=None\n",
    "    )\n",
    "    return validator\n",
    "\n",
    "\n",
    "def generateDataC(w_i,nodes):\n",
    "\n",
    "    \n",
    "    \n",
    "    T=np.empty([0])\n",
    "    K=np.empty([0])\n",
    "    SOLs=np.empty([0])\n",
    "    SOLw=np.empty([0])\n",
    "    krange= [(0.01 + 0.06*i*1) for i in range(0,20)]\n",
    "\n",
    "    deltaT = 0.01\n",
    "    \n",
    "    rate=1\n",
    "    for KR in krange:\n",
    "        begin=w_i* t_w\n",
    "        end=begin + t_w\n",
    "        sol=generateExactSolution(t_max,deltaT,KR,rate,KR,begin,end) ##NAO RODA, RETORNA MATRIZ DE ZEROS\n",
    "        \n",
    "        T=np.append(T,np.linspace(0,1,100))\n",
    "        K = np.append(K,np.full_like (sol.T[2],KR))\n",
    "        SOLs=np.append(SOLs,sol.T[0])\n",
    "        SOLw=np.append(SOLw,sol.T[1])\n",
    "    \n",
    "    \n",
    "    t = np.expand_dims(T, axis=-1)\n",
    "\n",
    "\n",
    "    k = np.expand_dims(K, axis=-1)\n",
    "\n",
    "    \n",
    "    Solx = np.expand_dims(SOLs, axis=-1)\n",
    "\n",
    "    \n",
    "    Solw = np.expand_dims(SOLw, axis=-1)\n",
    "   \n",
    "    \n",
    "    print(t,\"val set de \",begin,\"a \", end)\n",
    "    print(np.shape(t),np.shape(k))\n",
    "    \n",
    "    invar_numpy = {\"t\": t,\"K\":k}\n",
    "    outvar_numpy = {\n",
    "        \"x1\": Solx,\n",
    "        \"w\":Solw\n",
    "    }\n",
    "   \n",
    "    data = DeepONetConstraint.from_numpy(\n",
    "        nodes=nodes,\n",
    "        invar=invar_numpy,\n",
    "        outvar=outvar_numpy,\n",
    "        batch_size=len(krange)*10,\n",
    "        lambda_weighting=None\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "class SpringMass(PDE):\n",
    "    name = \"SpringMass\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        t = Symbol(\"t\")\n",
    "       \n",
    "        input_variables = {\"t\": t}\n",
    "\n",
    "        x = Function(\"x1\")(*input_variables)\n",
    "        w= Function(\"w\")(*input_variables)\n",
    "        self.equations = {}\n",
    "        self.equations[\"ode_x1\"] =10*(x*(x-0.4)*(1-x)-w) -x.diff(t)\n",
    "        self.equations[\"ode_w\"]  =0.5*(x*0.2-0.8*w) -w.diff(t)\n",
    "        \n",
    "@modulus.main(config_path=\"conf\", config_name=\"config\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "    \n",
    "    # make list of nodes to unroll graph on\n",
    "    sm = SpringMass()\n",
    "    sm.pprint()\n",
    "       \n",
    "    \n",
    "    flow_net = FullyConnectedArch(\n",
    "            input_keys=[Key(\"t\"), Key(\"K\") ],\n",
    "            output_keys=[Key(\"x1\"),Key(\"w\")],\n",
    "            layer_size=36,\n",
    "            nr_layers=4,\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "    time_window_net = MovingTimeWindowArch(flow_net, t_w)\n",
    "\n",
    "    nodes = sm.make_nodes() +[time_window_net.make_node(name=\"network\")]\n",
    "\n",
    "\n",
    "    for node in nodes:\n",
    "        print(node.__str__())\n",
    "   \n",
    "    # add constraints to solver\n",
    "    # make geometry\n",
    "    geo = Point1D(0)\n",
    "    \n",
    "    t_symbol = Symbol(\"t\")\n",
    "    x_symbol = Symbol(\"x1\")\n",
    "    k_symbol= Symbol(\"K\")\n",
    "    time_range = {t_symbol: (0,t_w )}\n",
    "    k_range= {k_symbol:(0,1)}\n",
    "    tr = {t_symbol: (0, t_w)}\n",
    "\n",
    "    # make domain\n",
    "        # make initial condition domain\n",
    "    ic_domain = Domain(\"initial_conditions\")\n",
    "\n",
    "  \n",
    "    # initial conditions\n",
    "    IC = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"x1\": k_symbol,\"w\":0},\n",
    "        batch_size=2000,\n",
    "        parameterization={**{t_symbol:0},**k_range},\n",
    "        lambda_weighting={\n",
    "            \"x1\": 100,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"w\": 100 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        \n",
    "        quasirandom=True,\n",
    "    )\n",
    "\n",
    "    ic_domain.add_constraint(IC, name=\"IC\")\n",
    "    \n",
    "        # solve over given time period\n",
    "    interior = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=1000,\n",
    "        parameterization={**tr,**k_range},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\": 100,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\": 100 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        quasirandom=True,\n",
    "    )\n",
    "    ic_domain.add_constraint(interior, name=\"interior\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    domains=[]\n",
    "    for i in range(1,n_w):\n",
    "\n",
    "        # make moving window domain\n",
    "        window_domain = Domain(\"window\"+str(i))\n",
    "\n",
    "        # solve over given time period\n",
    "        interior1 = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=2000,\n",
    "        parameterization={**tr,**k_range},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\": 100,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\": 100 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        quasirandom=True,\n",
    "\n",
    "        )\n",
    "        interior2 = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0,\"ode_w\":0.0},\n",
    "        batch_size=1000,\n",
    "        parameterization={**tr,**{k_symbol:(0.45,0.6)}},\n",
    "        #criteria=And(t_symbol > 0, t_symbol < 3),\n",
    "        lambda_weighting={\n",
    "            \"ode_x1\": 200,# + 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol),\n",
    "            \"ode_w\": 200 #+ 1000*x_symbol.diff(t_symbol)*x_symbol.diff(t_symbol)\n",
    "        },\n",
    "        quasirandom=True,\n",
    "\n",
    "        )\n",
    "        \n",
    "        \n",
    "        IC = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"x1_prev_step_diff\":0,\"w_prev_step_diff\":0},\n",
    "        batch_size=500,\n",
    "        parameterization={**{t_symbol:0},**k_range},\n",
    "        lambda_weighting={\n",
    "            \"x1_prev_step_diff\": 1000,\n",
    "            \"w_prev_step_diff\": 1000\n",
    "        },\n",
    "        \n",
    "        quasirandom=True,\n",
    "    )\n",
    "        \n",
    "    \n",
    "        \n",
    "        window_domain.add_constraint(IC, name=\"IC\")\n",
    "        window_domain.add_constraint(interior1, \"interior\")\n",
    "        #window_domain.add_constraint(interior2, \"interiorTr\")\n",
    "\n",
    "        domains.append(window_domain)\n",
    "    \n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    dom=[]\n",
    "    dom.append((1,ic_domain))\n",
    "\n",
    "    for domain in domains:\n",
    "        dom.append((1,domain))\n",
    "    print(cfg)\n",
    "    # make solver\n",
    "    #slv = Solver(cfg, domain)\n",
    "    #print(domains)\n",
    "    i=0\n",
    "    for a,d in dom:\n",
    "        print(d)\n",
    "        print(d.name)\n",
    "        d.add_inferencer(generateValidator(i,nodes))\n",
    "        d.add_constraint(generateDataC(i,nodes))\n",
    "        i=i+1\n",
    "    \n",
    "      \n",
    "    start_time = time.time()\n",
    "  \n",
    "    slv = SSolver(\n",
    "            cfg,\n",
    "            dom,\n",
    "            custom_update_operation=time_window_net.move_window,\n",
    "\n",
    "    )\n",
    "    slv.eval()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    global e\n",
    "    e=elapsed_time\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def join():\n",
    "    # Define the input arrays\n",
    "    array1 = [1, 2, 3]\n",
    "    array2 = ['A', 'B']\n",
    "\n",
    "    # Get the lengths of the input arrays\n",
    "    len1 = len(array1)\n",
    "    len2 = len(array2)\n",
    "\n",
    "    # Create an empty matrix to hold the combinations\n",
    "    matrix = np.empty((len1*len2, 2), dtype=object)\n",
    "\n",
    "    # Fill the matrix with the combinations\n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            matrix[i*len2+j, 0] = array1[i]\n",
    "            matrix[i*len2+j, 1] = array2[j]\n",
    "\n",
    "    # Print the resulting matrix\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def eval(X,t):\n",
    "\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "    #if(True):\n",
    "        global Input\n",
    "        global X0\n",
    "        X0=X\n",
    "        ASD= np.expand_dims(t[0][1:],-1)\n",
    "        if(1==1):\n",
    "            Input=ASD    \n",
    "        else:\n",
    "            print(np.shape(ASD))\n",
    "            intervals = np.array([int(i * 1 )for  i in range(0,10+1)])\n",
    "            print(intervals)\n",
    "            Input=  [ASD[(ASD >= intervals[i]) & (ASD < intervals[i+1])] for i in range(len(intervals)-1)]\n",
    "        run()     \n",
    "        u,i=load(X)\n",
    "\n",
    "    return u, e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from FHNCUDAlib import FHNCUDA\n",
    "import numpy as np\n",
    "from plotter import call\n",
    "import time as TIME\n",
    "x0=np.expand_dims(np.array([(0.03 + 0.0001*i*1) for i in range(0,10000)]),-1)\n",
    "dt,tt=0.01,10\n",
    "\n",
    "\n",
    "\n",
    "start_time = TIME.time()\n",
    "u,v ,t=FHNCUDA.run(x0,tt,dt,20)\n",
    "reftime = TIME.time()- start_time\n",
    "\n",
    "u_ref=np.array(u).flatten()\n",
    "\n",
    "print(\"Shape ref \",np.shape(u_ref))\n",
    "print(\"ref cuda time\",reftime)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = TIME.time()\n",
    "u,v ,t=FHNCUDA.run(x0,tt,dt*10,20/10)\n",
    "cudatime = TIME.time()- start_time\n",
    "u_num=np.array(u).flatten()\n",
    "\n",
    "print(\"Shape cudapred \",np.shape(u_num))\n",
    "print(\"cuda time\",cudatime)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_num)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "#print(\"id of max\",i, u_num[i], \"  -  \",u_net[i])\n",
    "\n",
    "\n",
    "\n",
    "start_time = TIME.time()\n",
    "u,time=eval(x0,t)\n",
    "nettime = TIME.time()- start_time\n",
    "u_net=u.flatten()\n",
    "\n",
    "print(\"Shape netpred \",np.shape(u_net))\n",
    "print(\"net time\", nettime)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_net)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "#print(\"id of max\",i, u_num[i], \"  -  \",u_net[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(u_net)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(u_num,\"b\")\n",
    "plt.plot(u_net,\"r\")\n",
    "plt.savefig(\"aa.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "e=lambda x:np.array(x).T\n",
    "\n",
    "invar={\"t\":e(t )  ,\"K\":e(x0)   }\n",
    "out={\"x1\":e(u_net),       }\n",
    "out_t={\"x1\":e(u_num),         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a86951c-2303-4f27-8646-7f12639aca08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:16:58.659663Z",
     "iopub.status.busy": "2023-05-07T18:16:58.659083Z",
     "iopub.status.idle": "2023-05-07T18:17:07.787770Z",
     "shell.execute_reply": "2023-05-07T18:17:07.787188Z",
     "shell.execute_reply.started": "2023-05-07T18:16:58.659640Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Number of rows in the CSV file:  10000 51\n",
      "Shape ref  (510000,)\n",
      "ref cuda time 0.8291070461273193\n",
      "5\n",
      "Number of rows in the CSV file:  10000 50\n",
      "Shape cudapred  (500000,)\n",
      "cuda time 0.8000023365020752\n",
      "Error Calculation\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/final/1P/fhn1Ppred.py\", line 539, in <module>\n",
      "    e=((u_ref-u_num)**2)**(1/2)\n",
      "ValueError: operands could not be broadcast together with shapes (510000,) (500000,) \n"
     ]
    }
   ],
   "source": [
    "!python fhn1Ppred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec5b32d-38eb-48bb-9bc1-41de8042fb3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:17:07.789243Z",
     "iopub.status.busy": "2023-05-07T18:17:07.788729Z",
     "iopub.status.idle": "2023-05-07T18:17:07.793645Z",
     "shell.execute_reply": "2023-05-07T18:17:07.792943Z",
     "shell.execute_reply.started": "2023-05-07T18:17:07.789217Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predComp.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile predComp.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e955af2-1480-4ff7-95e5-77d877133866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:17:07.794630Z",
     "iopub.status.busy": "2023-05-07T18:17:07.794447Z",
     "iopub.status.idle": "2023-05-07T18:17:08.026590Z",
     "shell.execute_reply": "2023-05-07T18:17:08.025835Z",
     "shell.execute_reply.started": "2023-05-07T18:17:07.794609Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python predComp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0e28099-f553-4f62-b9c0-d908a1a46e8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:17:08.029557Z",
     "iopub.status.busy": "2023-05-07T18:17:08.029005Z",
     "iopub.status.idle": "2023-05-07T18:17:10.030002Z",
     "shell.execute_reply": "2023-05-07T18:17:10.029339Z",
     "shell.execute_reply.started": "2023-05-07T18:17:08.029531Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_impl.layers.0.linear.weight loaded as\n",
      "Loading:  _impl.layers.0.linear.weight torch.Size([36, 2])  -> self.layer0.weight.data\n",
      "---\n",
      "_impl.layers.0.linear.weight_g loaded as\n",
      "Loading:  _impl.layers.0.linear.weight_g torch.Size([36, 1])  -> self.layer0.weight_g.data\n",
      "---\n",
      "_impl.layers.0.linear.bias loaded as\n",
      "Loading:  _impl.layers.0.linear.bias torch.Size([36])  -> self.layer0.bias.data\n",
      "---\n",
      "_impl.layers.1.linear.weight loaded as\n",
      "Loading:  _impl.layers.1.linear.weight torch.Size([36, 36])  -> self.layer1.weight.data\n",
      "---\n",
      "_impl.layers.1.linear.weight_g loaded as\n",
      "Loading:  _impl.layers.1.linear.weight_g torch.Size([36, 1])  -> self.layer1.weight_g.data\n",
      "---\n",
      "_impl.layers.1.linear.bias loaded as\n",
      "Loading:  _impl.layers.1.linear.bias torch.Size([36])  -> self.layer1.bias.data\n",
      "---\n",
      "_impl.layers.2.linear.weight loaded as\n",
      "Loading:  _impl.layers.2.linear.weight torch.Size([36, 36])  -> self.layer2.weight.data\n",
      "---\n",
      "_impl.layers.2.linear.weight_g loaded as\n",
      "Loading:  _impl.layers.2.linear.weight_g torch.Size([36, 1])  -> self.layer2.weight_g.data\n",
      "---\n",
      "_impl.layers.2.linear.bias loaded as\n",
      "Loading:  _impl.layers.2.linear.bias torch.Size([36])  -> self.layer2.bias.data\n",
      "---\n",
      "_impl.layers.3.linear.weight loaded as\n",
      "Loading:  _impl.layers.3.linear.weight torch.Size([36, 36])  -> self.layer3.weight.data\n",
      "---\n",
      "_impl.layers.3.linear.weight_g loaded as\n",
      "Loading:  _impl.layers.3.linear.weight_g torch.Size([36, 1])  -> self.layer3.weight_g.data\n",
      "---\n",
      "_impl.layers.3.linear.bias loaded as\n",
      "Loading:  _impl.layers.3.linear.bias torch.Size([36])  -> self.layer3.bias.data\n",
      "---\n",
      "_impl.final_layer.linear.weight loaded as\n",
      "Loading:  _impl.final_layer.linear.weight torch.Size([2, 36])  -> self.layer10.weight.data\n",
      "---\n",
      "_impl.final_layer.linear.bias loaded as\n",
      "Loading:  _impl.final_layer.linear.bias torch.Size([2])  -> self.layer10.bias.data\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import collections as coll\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "PATH = \"outputs/fhn1P/initial_conditions/network.0.pth\"\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "    \n",
    "pt.set_grad_enabled (False) \n",
    "numinputs=1\n",
    "numoutputs=2\n",
    "class net(nn.Module):\n",
    "    def __init__(self, numinputs, numoutputs):\n",
    "        super(net, self).__init__()\n",
    "        heigth=36\n",
    "        \n",
    "        self.layer0 = nn.utils.weight_norm(nn.Linear(numinputs, heigth),name='weight', dim=0).cuda()\n",
    "        self.layer1 = nn.utils.weight_norm(nn.Linear(heigth, heigth),name='weight', dim=0).cuda()\n",
    "        self.layer2 = nn.utils.weight_norm(nn.Linear(heigth, heigth),name='weight', dim=0).cuda()\n",
    "        self.layer3 = nn.utils.weight_norm(nn.Linear(heigth, heigth),name='weight', dim=0).cuda()\n",
    "        self.layer4 = nn.utils.weight_norm(nn.Linear(heigth, heigth),name='weight', dim=0).cuda()\n",
    "\n",
    "        self.layer10 = nn.Linear(heigth, numoutputs).cuda()\n",
    "        \n",
    "        self.layer0.eval()\n",
    "        self.layer1.eval()\n",
    "        self.layer2.eval()\n",
    "        self.layer3.eval()\n",
    "        self.layer10.eval()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = f.silu(self.layer0(x))\n",
    "        x1 = f.silu(self.layer1(x0))\n",
    "        x2 = f.silu(self.layer2(x1))\n",
    "        x3 = f.silu(self.layer3(x2))\n",
    "        x4 = f.silu(self.layer4(x3))\n",
    " \n",
    " \n",
    "        return self.layer10(x3)\n",
    "    \n",
    "    def load(self, od):\n",
    "        for k, v in od.items():\n",
    "            print(k,\"loaded as\")\n",
    "            if(k == '_impl.layers.0.linear.weight'): \n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer0.weight.data')\n",
    "                self.layer0.weight_v.data = v\n",
    "                self.layer0.weight_v.requires_grad = False\n",
    "            if(k == '_impl.layers.0.linear.weight_g'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer0.weight_g.data')\n",
    "                self.layer0.weight_g.data = v\n",
    "                self.layer0.weight_g.requires_grad = False\n",
    "            if(k == '_impl.layers.0.linear.bias'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer0.bias.data')\n",
    "                self.layer0.bias.data = v\n",
    "                self.layer0.bias.requires_grad = False\n",
    "            if(k == '_impl.layers.1.linear.weight'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer1.weight.data')\n",
    "                self.layer1.weight_v.data = v\n",
    "                self.layer1.weight_v.requires_grad = False\n",
    "            if(k == '_impl.layers.1.linear.weight_g'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer1.weight_g.data')\n",
    "                self.layer1.weight_g.data = v\n",
    "                self.layer1.weight_g.requires_grad = False\n",
    "            if(k == '_impl.layers.1.linear.bias'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer1.bias.data')\n",
    "                self.layer1.bias.data = v\n",
    "                self.layer1.weight_g.requires_grad = False\n",
    "            if(k == '_impl.layers.2.linear.weight'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer2.weight.data')\n",
    "                self.layer2.weight_v.data = v\n",
    "                self.layer2.weight_v.requires_grad = False\n",
    "            if(k == '_impl.layers.2.linear.weight_g'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer2.weight_g.data')\n",
    "                self.layer2.weight_g.data = v\n",
    "                self.layer2.weight_g.requires_grad = False\n",
    "            if(k == '_impl.layers.2.linear.bias'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer2.bias.data')\n",
    "                self.layer2.bias.data = v\n",
    "                self.layer2.bias.requires_grad = False\n",
    "                \n",
    "                \n",
    "            if(k == '_impl.layers.3.linear.weight'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer3.weight.data')\n",
    "                self.layer3.weight_v.data = v\n",
    "                self.layer3.weight_v.requires_grad = False\n",
    "            if(k == '_impl.layers.3.linear.weight_g'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer3.weight_g.data')\n",
    "                self.layer3.weight_g.data = v\n",
    "                self.layer3.weight_g.requires_grad = False\n",
    "            if(k == '_impl.layers.3.linear.bias'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer3.bias.data')\n",
    "                self.layer3.bias.data = v\n",
    "                self.layer3.bias.requires_grad = False  \n",
    "                \n",
    "                \n",
    "            if(k == '_impl.final_layer.linear.weight'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer10.weight.data')\n",
    "                self.layer10.weight.data = v\n",
    "                self.layer10.weight.requires_grad = False\n",
    "            if(k == '_impl.final_layer.linear.bias'):\n",
    "                print('Loading: ',k, np.shape(v), ' -> self.layer10.bias.data')\n",
    "                self.layer10.bias.data = v\n",
    "                self.layer10.bias.requires_grad = False\n",
    "            print(\"---\")\n",
    "\n",
    "    def dumpLayerWeightSizes(self):\n",
    "        print(self.layer0.weight.size())\n",
    "        print(self.layer1.weight.size())\n",
    "        print(self.layer2.weight.size())\n",
    "        print(self.layer3.weight.size())\n",
    "        print(self.layer4.weight.size())\n",
    "\n",
    "\n",
    "    def dumpLayerWeights(self):\n",
    "        print(self.layer0.weight)\n",
    "        print(self.layer1.weight)\n",
    "        print(self.layer2.weight)\n",
    "        print(self.layer3.weight)\n",
    "        print(self.layer4.weight)\n",
    "\n",
    "    def dumpLayerWeightGSizes(self):\n",
    "        print(self.layer0.weight_g.size())\n",
    "        print(self.layer1.weight_g.size())\n",
    "        print(self.layer2.weight_g.size())\n",
    "        print(self.layer3.weight_g.size())\n",
    "        print(self.layer4.weight_g.size())\n",
    "\n",
    "    def dumpLayerWeightGs(self):\n",
    "        print(self.layer0.weight_g)\n",
    "        print(self.layer1.weight_g)\n",
    "        print(self.layer2.weight_g)\n",
    "        print(self.layer3.weight_g)\n",
    "        print(self.layer4.weight_g)\n",
    "\n",
    "    def dumpLayerBiasSizes(self):\n",
    "        print(self.layer0.bias.size())\n",
    "        print(self.layer1.bias.size())\n",
    "        print(self.layer2.bias.size())\n",
    "        print(self.layer3.bias.size())\n",
    "        print(self.layer4.bias.size())\n",
    "\n",
    "    def dumpLayerBiases(self):\n",
    "        print(self.layer0.bias)\n",
    "        print(self.layer1.bias)\n",
    "        print(self.layer2.bias)\n",
    "        print(self.layer3.bias)\n",
    "        print(self.layer4.bias)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "net =net(2,2)\n",
    "\n",
    "od=pt.load(PATH)\n",
    "net.load(od)\n",
    "\n",
    "model=net\n",
    "import itertools\n",
    "\n",
    "def Modelrun(x=np.linspace(0, 1, num=10),t=np.linspace(0,10,num=10)):\n",
    "   \n",
    "    \n",
    "    X=np.zeros((2,len(t)*len(x)))\n",
    "    #print(itertools.product(x,t))\n",
    "    i=0\n",
    "    for a,b in itertools.product(x,t):\n",
    "        X[:,i]=(b,a)\n",
    "        i=i+1\n",
    "    #print(np.shape(X))\n",
    "    my2dspace = pt.tensor(X.T, requires_grad=False)\n",
    "    model.eval()\n",
    "\n",
    "    myOutput = model(my2dspace.float().cuda())\n",
    "    myCPUOutput = myOutput.cpu()\n",
    "\n",
    "\n",
    "    uu = myCPUOutput.numpy()\n",
    "\n",
    "    #print('uu: ', uu.T[0])\n",
    "\n",
    "    myCPUOutput.squeeze().detach().numpy()\n",
    "    return uu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4008a73-b576-4443-982d-1d70b68e5bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:17:10.031614Z",
     "iopub.status.busy": "2023-05-07T18:17:10.030990Z",
     "iopub.status.idle": "2023-05-07T18:17:10.351928Z",
     "shell.execute_reply": "2023-05-07T18:17:10.351213Z",
     "shell.execute_reply.started": "2023-05-07T18:17:10.031589Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Number of rows in the CSV file:  10 1000\n",
      "(10, 1000) (10000,)\n",
      "(1, 1001)\n"
     ]
    }
   ],
   "source": [
    "from FHNCUDAlib import FHNCUDA\n",
    "x0=np.expand_dims(np.linspace(0,1,10),-1)\n",
    "dt,tt=0.01,10\n",
    "t=np.expand_dims(np.linspace(0,tt,int(tt/dt)),-1)\n",
    "\n",
    "\n",
    "\n",
    "u,v,t=FHNCUDA.run(x0,tt,dt,1)\n",
    "print(np.shape(u),np.shape((np.array(v)).flatten()))\n",
    "print(np.shape(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80303df3-b7d6-4715-a496-cbb9cb43d9ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:17:10.353571Z",
     "iopub.status.busy": "2023-05-07T18:17:10.352859Z",
     "iopub.status.idle": "2023-05-07T18:17:10.582041Z",
     "shell.execute_reply": "2023-05-07T18:17:10.581189Z",
     "shell.execute_reply.started": "2023-05-07T18:17:10.353552Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1P'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1P\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1P'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"1P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d64c60-457f-4cdd-92be-8039ebe20c1e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T18:17:10.582728Z",
     "iopub.status.idle": "2023-05-07T18:17:10.583053Z",
     "shell.execute_reply": "2023-05-07T18:17:10.582908Z",
     "shell.execute_reply.started": "2023-05-07T18:17:10.582892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from load import load\n",
    "X=np.linspace(0,2,10)\n",
    "a=load(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d9ca8-1ad6-4547-9ca0-37c3fb79ca53",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T18:17:10.584617Z",
     "iopub.status.idle": "2023-05-07T18:17:10.585119Z",
     "shell.execute_reply": "2023-05-07T18:17:10.584972Z",
     "shell.execute_reply.started": "2023-05-07T18:17:10.584955Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from FHNCUDAlib import FHNCUDA\n",
    "import numpy as np\n",
    "from plotter import call\n",
    "import time as TIME\n",
    "x0=np.expand_dims(np.array([(0.03 + 0.00005*i*1) for i in range(0,20000)]),-1)\n",
    "dt,tt=0.0001,10\n",
    "\n",
    "\n",
    "\n",
    "start_time = TIME.time()\n",
    "u,v ,t=FHNCUDA.run(x0,tt,dt,200)\n",
    "reftime = TIME.time()- start_time\n",
    "\n",
    "u_ref=np.array(u).flatten()\n",
    "\n",
    "print(\"Solving for \",len(x0),\"cells in \" ,int(np.shape(u_ref)[0]/len(x0)),\"timepoints\" )\n",
    "print(\"Shape ref \",np.shape(u_ref))\n",
    "print(\"ref cuda time\",reftime)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = TIME.time()\n",
    "u,v ,t=FHNCUDA.run(x0,tt,dt*100,200/100)\n",
    "cudatime = TIME.time()- start_time\n",
    "u_num=np.array(u).flatten()\n",
    "#print(np.unique(t))\n",
    "\n",
    "print(\"Shape cudapred \",np.shape(u_num))\n",
    "print(\"cuda time\",cudatime)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_num)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "#print(\"id of max\",i, u_num[i], \"  -  \",u_net[i])\n",
    "\n",
    "x0 = [item for sublist in x0 for item in sublist]\n",
    "t = [item for sublist in t for item in sublist]\n",
    "#print(x0)\n",
    "#print(np.shape(x0),np.shape(t))\n",
    "\n",
    "start_time = TIME.time()\n",
    "u=Modelrun(x0,t[1:])\n",
    "nettime = TIME.time()- start_time\n",
    "\n",
    "u_net=u.T[0].flatten()\n",
    "\n",
    "print(\"Shape netpred \",np.shape(u_net))\n",
    "print(\"net time\", nettime)\n",
    "print(\"Error Calculation\")\n",
    "e=((u_ref-u_net)**2)**(1/2)\n",
    "print(\"mean\",np.mean(e))\n",
    "m=np.max(e)\n",
    "print(\"max\",m)\n",
    "i=[a for a in range(len(e)) if e[a]==m]\n",
    "#print(\"id of max\",i, u_num[i], \"  -  \",u_net[i])\n",
    "\n",
    "\n",
    "\n",
    "#print(u_net)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(u_num,\"b\")\n",
    "plt.plot(u_net,\"r\")\n",
    "plt.savefig(\"aa.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "e=lambda x:np.array(x).T\n",
    "\n",
    "invar={\"t\":e(t )  ,\"K\":e(x0)   }\n",
    "out={\"x1\":e(u_net),       }\n",
    "out_t={\"x1\":e(u_num),         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ce6af-2bc1-4887-bd0b-331daa0c9722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360b37c-d0ab-4b6d-9e3a-f78ec04034b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b4329-bbb6-4587-9e1c-916cd03f0422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
